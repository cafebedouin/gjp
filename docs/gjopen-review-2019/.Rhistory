# Preliminaries
# Define basepath and set working directory:
basepath = "~/Documents/programs/R/forecasting"
setwd(basepath)
# Preventing scientific notation in graphs
options(scipen=999)
#################################################
# Load libraries. If library X is not installed
# you can install it with this command at the R prompt:
# install.packages('X')
library(data.table)
library(lubridate)
library(stringr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
library(corrplot)
library(hydroGOF)
library(Hmisc)
library(forecast)
library(tseries)
#################################################
# Import, organize and output csv data
# Import csv using current masie data
co2_data <- read.csv("./data/co2_doy.csv", skip=0, header=FALSE)
# Adding column names, changing sea name to sea ice
colnames(co2_data) <- c("Year", "Day", "Value")
# Reshape the three columns into a table, fix names, and export csv file
co2_table <- reshape(co2_data, direction="wide", idvar="Day", timevar="Year")
names(co2_table) <- gsub("Value.", "", names(co2_table))
# Creating a cvs file of changed data
# write.csv(co2_table, file=paste0("./output/co2-table-", co2_date, ".csv"))
View(co2_data)
}
defun_test2()
# defun_test2.R
#################################################
# Description: This script scrape yield data
# from the Treasury website or downloaded file.
# It is meant as a test environment for
# progamming new functions.
rm(list=ls()) # Clear memory
gc()
# Replace defaults in function to desired, or call the function from console
defun_test2 <- function(day_one=1,
last_day=336) {
days_start <- day_one
days_end <- last_day
co2_date <- Sys.Date()
#################################################
# Preliminaries
# Define basepath and set working directory:
basepath = "~/Documents/programs/R/forecasting"
setwd(basepath)
# Preventing scientific notation in graphs
options(scipen=999)
#################################################
# Load libraries. If library X is not installed
# you can install it with this command at the R prompt:
# install.packages('X')
library(data.table)
library(lubridate)
library(stringr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
library(corrplot)
library(hydroGOF)
library(Hmisc)
library(forecast)
library(tseries)
#################################################
# Import, organize and output csv data
# Import csv using current masie data
co2_data <- read.csv("./data/co2_doy.csv", skip=0, header=FALSE)
# Adding column names, changing sea name to sea ice
colnames(co2_data) <- c("Year", "Day", "Value")
# Reshape the three columns into a table, fix names, and export csv file
co2_table <- reshape(co2_data, direction="wide", idvar="Day", timevar="Year")
names(co2_table) <- gsub("Value.", "", names(co2_table))
# Creating a cvs file of changed data
# write.csv(co2_table, file=paste0("./output/co2-table-", co2_date, ".csv"))
ts = ts(t(co2_data[1:4005, ]))
plot(ts[1,],type=’o’,col=’blue’)
}
# defun_test2.R
#################################################
# Description: This script scrape yield data
# from the Treasury website or downloaded file.
# It is meant as a test environment for
# progamming new functions.
rm(list=ls()) # Clear memory
gc()
# Replace defaults in function to desired, or call the function from console
defun_test2 <- function(day_one=1,
last_day=336) {
days_start <- day_one
days_end <- last_day
co2_date <- Sys.Date()
#################################################
# Preliminaries
# Define basepath and set working directory:
basepath = "~/Documents/programs/R/forecasting"
setwd(basepath)
# Preventing scientific notation in graphs
options(scipen=999)
#################################################
# Load libraries. If library X is not installed
# you can install it with this command at the R prompt:
# install.packages('X')
library(data.table)
library(lubridate)
library(stringr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
library(corrplot)
library(hydroGOF)
library(Hmisc)
library(forecast)
library(tseries)
#################################################
# Import, organize and output csv data
# Import csv using current masie data
co2_data <- read.csv("./data/co2_doy.csv", skip=0, header=FALSE)
# Adding column names, changing sea name to sea ice
colnames(co2_data) <- c("Year", "Day", "Value")
# Reshape the three columns into a table, fix names, and export csv file
co2_table <- reshape(co2_data, direction="wide", idvar="Day", timevar="Year")
names(co2_table) <- gsub("Value.", "", names(co2_table))
# Creating a cvs file of changed data
# write.csv(co2_table, file=paste0("./output/co2-table-", co2_date, ".csv"))
ts = ts(t(co2_data[1:4005, ]))
plot(ts[1,], type='o',col='blue')
}
defun_test2()
# defun_test2.R
#################################################
# Description: This script scrape yield data
# from the Treasury website or downloaded file.
# It is meant as a test environment for
# progamming new functions.
rm(list=ls()) # Clear memory
gc()
# Replace defaults in function to desired, or call the function from console
defun_test2 <- function(day_one=1,
last_day=336) {
days_start <- day_one
days_end <- last_day
co2_date <- Sys.Date()
#################################################
# Preliminaries
# Define basepath and set working directory:
basepath = "~/Documents/programs/R/forecasting"
setwd(basepath)
# Preventing scientific notation in graphs
options(scipen=999)
#################################################
# Load libraries. If library X is not installed
# you can install it with this command at the R prompt:
# install.packages('X')
library(data.table)
library(lubridate)
library(stringr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
library(corrplot)
library(hydroGOF)
library(Hmisc)
library(forecast)
library(tseries)
#################################################
# Import, organize and output csv data
# Import csv using current masie data
co2_data <- read.csv("./data/co2_doy.csv", skip=0, header=FALSE)
# Adding column names, changing sea name to sea ice
colnames(co2_data) <- c("Year", "Day", "Value")
# Reshape the three columns into a table, fix names, and export csv file
co2_table <- reshape(co2_data, direction="wide", idvar="Day", timevar="Year")
names(co2_table) <- gsub("Value.", "", names(co2_table))
# Creating a cvs file of changed data
# write.csv(co2_table, file=paste0("./output/co2-table-", co2_date, ".csv"))
ts = ts(t(co2_data[1:4005, ]))
plot(ts[,1], type='o',col='blue')
}
defun_test2()
# defun_test2.R
#################################################
# Description: This script scrape yield data
# from the Treasury website or downloaded file.
# It is meant as a test environment for
# progamming new functions.
rm(list=ls()) # Clear memory
gc()
# Replace defaults in function to desired, or call the function from console
defun_test2 <- function(day_one=1,
last_day=336) {
days_start <- day_one
days_end <- last_day
co2_date <- Sys.Date()
#################################################
# Preliminaries
# Define basepath and set working directory:
basepath = "~/Documents/programs/R/forecasting"
setwd(basepath)
# Preventing scientific notation in graphs
options(scipen=999)
#################################################
# Load libraries. If library X is not installed
# you can install it with this command at the R prompt:
# install.packages('X')
library(data.table)
library(lubridate)
library(stringr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
library(corrplot)
library(hydroGOF)
library(Hmisc)
library(forecast)
library(tseries)
#################################################
# Import, organize and output csv data
# Import csv using current masie data
co2_data <- read.csv("./data/co2_doy.csv", skip=0, header=FALSE)
# Adding column names, changing sea name to sea ice
colnames(co2_data) <- c("Year", "Day", "Value")
# Reshape the three columns into a table, fix names, and export csv file
co2_table <- reshape(co2_data, direction="wide", idvar="Day", timevar="Year")
names(co2_table) <- gsub("Value.", "", names(co2_table))
# Creating a cvs file of changed data
# write.csv(co2_table, file=paste0("./output/co2-table-", co2_date, ".csv"))
ts = ts(t(co2_data[1:4005,]))
plot(ts[,1], type='o',col='blue')
}
defun_test2()
# defun_test2.R
#################################################
# Description: This script scrape yield data
# from the Treasury website or downloaded file.
# It is meant as a test environment for
# progamming new functions.
rm(list=ls()) # Clear memory
gc()
# Replace defaults in function to desired, or call the function from console
defun_test2 <- function(day_one=1,
last_day=336) {
days_start <- day_one
days_end <- last_day
co2_date <- Sys.Date()
#################################################
# Preliminaries
# Define basepath and set working directory:
basepath = "~/Documents/programs/R/forecasting"
setwd(basepath)
# Preventing scientific notation in graphs
options(scipen=999)
#################################################
# Load libraries. If library X is not installed
# you can install it with this command at the R prompt:
# install.packages('X')
library(data.table)
library(lubridate)
library(stringr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(reshape2)
library(corrplot)
library(hydroGOF)
library(Hmisc)
library(forecast)
library(tseries)
#################################################
# Import, organize and output csv data
# Import csv using current masie data
co2_data <- read.csv("./data/co2_doy.csv", skip=0, header=FALSE)
# Adding column names, changing sea name to sea ice
colnames(co2_data) <- c("Year", "Day", "Value")
# Reshape the three columns into a table, fix names, and export csv file
co2_table <- reshape(co2_data, direction="wide", idvar="Day", timevar="Year")
names(co2_table) <- gsub("Value.", "", names(co2_table))
# Creating a cvs file of changed data
# write.csv(co2_table, file=paste0("./output/co2-table-", co2_date, ".csv"))
ts = ts(t(co2_data[1:4005,]))
View(ts)
plot(ts[,1], type='o',col='blue')
}
defun_test2()
install.packages("rticles")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
source("R/gjopen-review-2019.R")
x <- knitr::kable(scores, format = "markdown", caption = "Brier Scores: 2019")
column_spec(x, 2, width="25em")
library(kableExtra)
source("R/gjopen-review-2019.R")
x <- knitr::kable(scores, format = "markdown", caption = "Brier Scores: 2019")
column_spec(x, 3-6, width="5em")
colnames(scores) <- c("Date", "Question", "%", "Brier", "Median", "Accuracy")
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "%", "Brier", "Median", "Accuracy")
View(scores)
knitr::opts_chunk$set(echo = TRUE)
source("R/gjopen-review-2019.R")
x <- knitr::kable(scores, caption = "Brier Scores: 2019")
source("R/gjopen-review-2019.R")
x <- knitr::kable(scores, booktabs = T, caption = "Brier Scores: 2019")
library(kableExtra)
source("R/gjopen-review-2019.R")
x <- knitr::kable(scores,
booktabs = T,
format = "markdown",
caption = "Brier Scores: 2019")
column_spec(x, 3:6, width = "50em")
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "%", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 20)
View(scores)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=FALSE)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=FALSE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "-%-", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
View(scores)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "-%-", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 | Brier <0.25)
View(good)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(scores$Time)
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 | Brier < 0.25)
View(good)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
View(scores)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
scores$Time <- as.numeric(scores$Time)
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 | Brier < 0.25)
View(good)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", df$value))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 | Brier < 0.25)
View(good)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", df$value))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 & Brier < 0.25 & Time < 75%)
View(good)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", scores$Time))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 & Brier < 0.25 & Time < 75%)
View(good)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", scores$Time))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 & Brier < 0.25)
View(good)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", scores$Time))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 & Brier < 0.25 & Time > 75)
View(good)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", scores$Time))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 & Brier < 0.25 & Time > 75)
bad <- filter(scores, Accuracy >= .10 & Brier > 0.25 & Time > 75)
View(bad)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", scores$Time))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 & Brier < 0.25 & Time > 75)
View(good)
bad <- filter(scores, Accuracy >= .10 & Brier > 0.25 & Time > 75)
View(bad)
library(kableExtra)
source("R/gjopen-review-2019.R")
knitr::kable(bad,
booktabs = T,
format = "markdown",
caption = "Bad Brier Scores: 2019")
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", scores$Time))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 & Brier < 0.25 & Time > 75)
bad <- filter(scores, Accuracy >= .10 & Brier > 0.25 & Time > 75)
above <- filter(scores, Brier > 1)
View(good)
View(bad)
View(above)
setwd("/home/scott/Documents/R/forecasting/docs/gjopen-review-2019")
library(dplyr)
scores <- read.csv("data/gjopen-scores-2019.csv", skip=0, header=TRUE)
scores$Date.Ended <- as.Date(scores$Date.Ended, format = '%b %d, %Y %I:%M%p')
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Time <- as.numeric(gsub("[\\%,]", "", scores$Time))
scores$Brier <- as.numeric(scores$Brier)
scores$Median <- as.numeric(scores$Median)
scores$Accuracy <- as.numeric(scores$Accuracy)
colnames(scores) <- c("Date", "Question", "Time", "Brier", "Median", "Accuracy")
scores$Question <- substr(scores$Question, 0, 40)
good <- filter(scores, Accuracy <= -.10 & Brier < 0.25 & Time > 75)
bad <- filter(scores, Accuracy >= .10 & Brier > 0.25 & Time > 75)
above <- filter(scores, Brier > 1)
View(good)
View(bad)
View(above)
View(scores)
